{"ast":null,"code":"var _jsxFileName = \"/Users/vishwajithp/devjams-unfaked/frontend/src/components/Models.js\";\nimport React from 'react';\nimport \"../index.css\";\nimport { Fragment as _Fragment, jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst About = () => {\n  const info = [{\n    head: \"What are Mel-Frequency Cepstral Coefficients (MFCC), and how are they applied in audio and video processing?\",\n    info: /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: \"Mel-frequency cepstral coefficients (MFCC) are widely used in speech and audio processing to represent the short-term power spectrum of a sound signal. This is crucial for analyzing voice patterns in speech processing. In deepfake detection, they help identify discrepancies in audio by capturing subtle inconsistencies in speech characteristics in manipulated audio.\"\n    }, void 0, false)\n  }, {\n    head: \"How does a digital forensics-based model detect deepfakes?\",\n    info: /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: \"This model performs a digital forensic analysis by examining various aspects of a video to detect potential manipulation. It inspects the metadata for traces of editing software or unusual codecs, analyzes frame consistency to identify unnatural transitions, checks facial landmarks for limited or abnormal movements, and scrutinizes compression artifacts for irregular patterns. These combined techniques allow the model to effectively assess whether a video is likely to be a deepfake.\"\n    }, void 0, false)\n  }, {\n    head: \"How does LipNet work, and what role does it play in deepfake detection?\",\n    info: /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: \"LipNet is a deep learning model designed to read lips by analyzing video frames of a speaker's mouth movements. It captures the temporal dynamics of lip motion to predict spoken words without relying on audio input. In the context of deepfake detection, LipNet can be used to detect discrepancies between visual lip movements and the corresponding audio. Since deepfakes often have subtle misalignments between speech and lip movement, LipNet can help identify these inconsistencies, making it a powerful tool in detecting video-based manipulation.\"\n    }, void 0, false)\n  }, {\n    head: \"What is MesoNet, and how does it contribute to identifying manipulated facial features in videos?\",\n    info: /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: \"MesoNet is a deep learning architecture specifically designed for deepfake detection, focusing on identifying manipulated facial features in videos. It analyzes mesoscopic properties\\u2014mid-level patterns in facial images that are altered during the creation of deepfakes. By detecting subtle artifacts and distortions introduced by deepfake generation methods, MesoNet can differentiate between real and fake faces.\"\n    }, void 0, false)\n  }, {\n    head: \"How does gaze tracking improve deepfake detection?\",\n    info: /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: \"Gaze tracking is a technique that monitors eye movements to detect irregularities, such as abnormal blinking intervals or unusual blink counts, which are often signs of deepfake manipulations. By calculating the eye aspect ratio (EAR), these irregularities can be quantified to identify mismatches between expected and observed blink patterns, thus helping in detecting deepfakes.\"\n    }, void 0, false)\n  }];\n  const getItems = () => {\n    return info;\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"flex flex-col w-full h-full about overflow-hidden pt-[10vh] flex flex-col items-center justify-center overflow-hidden\",\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"w-[90vw] lg:w-[95vw] h-auto border-black my-12 border-4 shadow-[-5px_5px_0_0_#000000] lg:shadow-[-10px_10px_0_0_#000000] flex flex-col items-center\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"bg-white h-[2vh] lg:h-[8vh] w-full flex items-center border-black border-b-2 pl-[0.5vw]\",\n        children: /*#__PURE__*/_jsxDEV(\"img\", {\n          src: \"/signal.svg\",\n          alt: \"Traffic Signal\",\n          className: \"h-[1vh] lg:h-[5vh]\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 65,\n          columnNumber: 17\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"flex flex-col justify-center items-center h-1/5 font-protest border-b-4 lg:border-b-8 border-white w-full\",\n        children: /*#__PURE__*/_jsxDEV(\"h1\", {\n          className: \"text-white text-[3vh] lg:text-[6vh] font-vt323\",\n          children: \"About the Models\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 68,\n          columnNumber: 9\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 67,\n        columnNumber: 7\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"flex flex-col items-center  w-full \",\n        children: getItems().map((item, index) => /*#__PURE__*/_jsxDEV(\"div\", {\n          className: `flex font-vt323 border-b-2 lg:border-b-4 border-white py-6 w-full  ${index % 2 === 0 ? \"flex-row-reverse\" : \"flex-row\"}`,\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"flex-1\",\n            children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n              className: \"text-[3vh] lg:text-[5vh] font-bold px-4 text-cyan-300\",\n              children: item.head\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 81,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"text-[2.5vh] lg:text-[4vh] mt-2 text-yellow-400 font-semibold px-8\",\n              children: item.info\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 82,\n              columnNumber: 15\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 80,\n            columnNumber: 13\n          }, this)\n        }, index, false, {\n          fileName: _jsxFileName,\n          lineNumber: 74,\n          columnNumber: 11\n        }, this))\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 71,\n        columnNumber: 7\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 62,\n    columnNumber: 5\n  }, this);\n};\n_c = About;\nexport default About;\nvar _c;\n$RefreshReg$(_c, \"About\");","map":{"version":3,"names":["React","Fragment","_Fragment","jsxDEV","_jsxDEV","About","info","head","children","getItems","className","src","alt","fileName","_jsxFileName","lineNumber","columnNumber","map","item","index","_c","$RefreshReg$"],"sources":["/Users/vishwajithp/devjams-unfaked/frontend/src/components/Models.js"],"sourcesContent":["import React from 'react';\nimport \"../index.css\";\n\nconst About = () => {\n  const info = [\n    {\n      head: \"What are Mel-Frequency Cepstral Coefficients (MFCC), and how are they applied in audio and video processing?\",\n      info: (\n        <>Mel-frequency cepstral coefficients (MFCC) are widely used in speech and audio processing to\n        represent the short-term power spectrum of a sound signal. This is crucial for analyzing voice\n        patterns in speech processing. In deepfake detection, they help identify discrepancies in audio by\n        capturing subtle inconsistencies in speech characteristics in manipulated audio.</>\n      ),\n    },\n    {\n      head: \"How does a digital forensics-based model detect deepfakes?\",\n      info: (\n        <>This model performs a digital forensic analysis by examining various aspects of a video to detect\n        potential manipulation. It inspects the metadata for traces of editing software or unusual codecs,\n        analyzes frame consistency to identify unnatural transitions, checks facial landmarks for limited or\n        abnormal movements, and scrutinizes compression artifacts for irregular patterns. These combined\n        techniques allow the model to effectively assess whether a video is likely to be a deepfake.</>\n      ),\n    },\n    {\n      head: \"How does LipNet work, and what role does it play in deepfake detection?\",\n      info: (\n        <>LipNet is a deep learning model designed to read lips by analyzing video frames of a speaker's\n        mouth movements. It captures the temporal dynamics of lip motion to predict spoken words without\n        relying on audio input. In the context of deepfake detection, LipNet can be used to detect\n        discrepancies between visual lip movements and the corresponding audio. Since deepfakes often\n        have subtle misalignments between speech and lip movement, LipNet can help identify these\n        inconsistencies, making it a powerful tool in detecting video-based manipulation.</>\n      ),\n    },\n    {\n      head: \"What is MesoNet, and how does it contribute to identifying manipulated facial features in videos?\",\n      info: (\n        <>MesoNet is a deep learning architecture specifically designed for deepfake detection, focusing on\n        identifying manipulated facial features in videos. It analyzes mesoscopic propertiesâ€”mid-level\n        patterns in facial images that are altered during the creation of deepfakes. By detecting subtle\n        artifacts and distortions introduced by deepfake generation methods, MesoNet can differentiate\n        between real and fake faces.</>\n      ),\n    },\n    {\n      head: \"How does gaze tracking improve deepfake detection?\",\n      info: (\n        <>Gaze tracking is a technique that monitors eye movements to detect irregularities, such as abnormal\n        blinking intervals or unusual blink counts, which are often signs of deepfake manipulations. By\n        calculating the eye aspect ratio (EAR), these irregularities can be quantified to identify mismatches\n        between expected and observed blink patterns, thus helping in detecting deepfakes.</>\n      ),\n    },\n  ];\n\n  const getItems = () => {\n    return info;\n  };\n\n  return (\n    <div className=\"flex flex-col w-full h-full about overflow-hidden pt-[10vh] flex flex-col items-center justify-center overflow-hidden\">\n      <div className=\"w-[90vw] lg:w-[95vw] h-auto border-black my-12 border-4 shadow-[-5px_5px_0_0_#000000] lg:shadow-[-10px_10px_0_0_#000000] flex flex-col items-center\">\n            <div className=\"bg-white h-[2vh] lg:h-[8vh] w-full flex items-center border-black border-b-2 pl-[0.5vw]\">\n                <img src=\"/signal.svg\" alt=\"Traffic Signal\" className=\"h-[1vh] lg:h-[5vh]\" />\n            </div>\n      <div className=\"flex flex-col justify-center items-center h-1/5 font-protest border-b-4 lg:border-b-8 border-white w-full\">\n        <h1 className=\"text-white text-[3vh] lg:text-[6vh] font-vt323\">About the Models</h1>\n      </div>\n\n      <div className=\"flex flex-col items-center  w-full \">\n        \n        {getItems().map((item, index) => (\n          <div\n            key={index}\n            className={`flex font-vt323 border-b-2 lg:border-b-4 border-white py-6 w-full  ${\n              index % 2 === 0 ? \"flex-row-reverse\" : \"flex-row\"\n            }`}\n          >\n            <div className=\"flex-1\">\n              <h2 className=\"text-[3vh] lg:text-[5vh] font-bold px-4 text-cyan-300\">{item.head}</h2>\n              <p className=\"text-[2.5vh] lg:text-[4vh] mt-2 text-yellow-400 font-semibold px-8\">{item.info}</p>\n            </div>\n            \n          </div>\n        ))}\n      </div>\n    </div>\n    </div>\n  );\n};\n\nexport default About;\n"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAO,cAAc;AAAC,SAAAC,QAAA,IAAAC,SAAA,EAAAC,MAAA,IAAAC,OAAA;AAEtB,MAAMC,KAAK,GAAGA,CAAA,KAAM;EAClB,MAAMC,IAAI,GAAG,CACX;IACEC,IAAI,EAAE,8GAA8G;IACpHD,IAAI,eACFF,OAAA,CAAAF,SAAA;MAAAM,QAAA,EAAE;IAG8E,gBAAE;EAEtF,CAAC,EACD;IACED,IAAI,EAAE,4DAA4D;IAClED,IAAI,eACFF,OAAA,CAAAF,SAAA;MAAAM,QAAA,EAAE;IAI0F,gBAAE;EAElG,CAAC,EACD;IACED,IAAI,EAAE,yEAAyE;IAC/ED,IAAI,eACFF,OAAA,CAAAF,SAAA;MAAAM,QAAA,EAAE;IAK+E,gBAAE;EAEvF,CAAC,EACD;IACED,IAAI,EAAE,mGAAmG;IACzGD,IAAI,eACFF,OAAA,CAAAF,SAAA;MAAAM,QAAA,EAAE;IAI0B,gBAAE;EAElC,CAAC,EACD;IACED,IAAI,EAAE,oDAAoD;IAC1DD,IAAI,eACFF,OAAA,CAAAF,SAAA;MAAAM,QAAA,EAAE;IAGgF,gBAAE;EAExF,CAAC,CACF;EAED,MAAMC,QAAQ,GAAGA,CAAA,KAAM;IACrB,OAAOH,IAAI;EACb,CAAC;EAED,oBACEF,OAAA;IAAKM,SAAS,EAAC,uHAAuH;IAAAF,QAAA,eACpIJ,OAAA;MAAKM,SAAS,EAAC,qJAAqJ;MAAAF,QAAA,gBAC9JJ,OAAA;QAAKM,SAAS,EAAC,yFAAyF;QAAAF,QAAA,eACpGJ,OAAA;UAAKO,GAAG,EAAC,aAAa;UAACC,GAAG,EAAC,gBAAgB;UAACF,SAAS,EAAC;QAAoB;UAAAG,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAE;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC5E,CAAC,eACZZ,OAAA;QAAKM,SAAS,EAAC,2GAA2G;QAAAF,QAAA,eACxHJ,OAAA;UAAIM,SAAS,EAAC,gDAAgD;UAAAF,QAAA,EAAC;QAAgB;UAAAK,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACjF,CAAC,eAENZ,OAAA;QAAKM,SAAS,EAAC,qCAAqC;QAAAF,QAAA,EAEjDC,QAAQ,CAAC,CAAC,CAACQ,GAAG,CAAC,CAACC,IAAI,EAAEC,KAAK,kBAC1Bf,OAAA;UAEEM,SAAS,EAAE,sEACTS,KAAK,GAAG,CAAC,KAAK,CAAC,GAAG,kBAAkB,GAAG,UAAU,EAChD;UAAAX,QAAA,eAEHJ,OAAA;YAAKM,SAAS,EAAC,QAAQ;YAAAF,QAAA,gBACrBJ,OAAA;cAAIM,SAAS,EAAC,uDAAuD;cAAAF,QAAA,EAAEU,IAAI,CAACX;YAAI;cAAAM,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAK,CAAC,eACtFZ,OAAA;cAAGM,SAAS,EAAC,oEAAoE;cAAAF,QAAA,EAAEU,IAAI,CAACZ;YAAI;cAAAO,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAI,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC9F;QAAC,GARDG,KAAK;UAAAN,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAUP,CACN;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACC,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACD,CAAC;AAEV,CAAC;AAACI,EAAA,GAvFIf,KAAK;AAyFX,eAAeA,KAAK;AAAC,IAAAe,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}